 * Add dependecy between K8S job and K8S driver pod so when we delete the job it deletes the driver pod. Executors pods are already dependent on the driver so cascade delete will happen
 * Change the autoscaler step to scale faster
 * Change the fargate profile adding a label to allow job and driver being scheduled quickly
 * Check why spark-submit fails with non root user in the spark image (.ivy error then user error...)
 * Use Amazon EKS native labels instead of custom ones

    beta.kubernetes.io/os: linux
    failure-domain.beta.kubernetes.io/zone: us-east-1c
    kubernetes.io/os: linux
    node-lifecycle: on-demand      node-lifecycle: spot  (eks.amazonaws.com/capacityType: ON_DEMAND for managed nodegroups)
    topology.kubernetes.io/zone: us-east-1c

 * Add anti affinity rules for avoid mixing Spark workloads with different SLA
